---
title: "[Summary] Unifying Generative and Dense Retrieval for Sequential Recommendation" 
date: 2025-01-04
tags: 
- Recommender system
- LLM 
draft: true 
---

## TL;DR 
Common item retrieval methods for item recommendation generate user and item embeddings and predict the relevance by inner product computation between the user and all item representations. However, this approach requires storing the embeddings for each item which might not be scalable enough for large scale items (requires both computation and storage). Recently proposed generative retrieval directly predicting item indices using a generative model trained on semantic IDs that encapsulate items’ semantic information 

We compare these two approaches under controlled conditions on academic
benchmarks 
* propose propose LIGER ( L everagIng dense retrieval for GEnerative Retrieval), a hybrid
model that combines the strengths of these two widely used methods. 
to enhancing cold-start item recommendation in the datasets evaluated.



Items are indexed by “semantic IDs”  which encapsulate their semantic characteristics. During the recommendation process, the model employs beam search decoding to predict the semantic ID (SID) of the next item based on the user’s previous interactions.
This method not only reduces the need for storing individual item embeddings


# Dense vs Generative Retrieval 


**Generative retrieval overview.**
The first stage involves collecting textual descriptions for each item based on their attributes. These
descriptions serve as inputs to a content model (e.g., a language encoder) that produces item’s text embeddings, subsequently quantized by an RQ-VAE  to attribute a semantic ID for each item.

In the second stage of training, the item text representation and the trained RQ-VAE model are
discarded, retaining only the semantic IDs. 
For each interaction history indexed by item IDs, the item IDs are replaced with their corresponding semantic IDs.
Given the semantic IDs of the last n items a user interacted with, the Transformer model is then optimized to predict the next semantic ID sequence.
During inference, a set of candidate items is retrieved using beam search over the trained Transformer,
selecting items based on their semantic IDs. 



we refer to the embedding-centric paradigm in this paper as (sequential) dense retrieval. 

The dense retrieval approach demonstrates stronger performance than generative
retrieval on both in-set and cold-start item predictions across the datasets we tested.


generative retrieval method struggles with cold-start items, achieving close-to-zero performance
on most datasets except for the Amazon Sports dataset


There are notable differences between the two implemented methods: 
1. Different Item Indexing and Number of Embeddings: As discussed in Section 2.1, representing N item requires the dense retrieval method to learn and store O(N) embeddings. In contrast, the semantic-ID-based generative retrieval method only requires O(t) tokens, where tm ≈ N , and m is the length of the semantic ID tuple. However, it remains unclear whether
the learned semantic ID can sufficiently capture the item’s semantic meaning and effectively replace the item
2. Text Representation Input: Dense retrieval utilize the item’s text representation as additional input;
3. Prediction Mechanism: Dense retrieval relies on maximum inner product search in the embedding
space, whereas generative retrieval predicts the next item through next-token prediction via beam search.


![Dense_vs_generative_retrieval](/posts/20250104_unifying_generative_and_dense_retrieval_for_sequential_recommendation/dense_vs_generative_retrieval.png)

# Method for Combining Dense and Generative Retrieval

Our SID-based hybrid model applies dense retrieval
to a limited set of candidates generated by a generative retrieval module, retaining the minimal storage
requirements of generative retrieval while significantly improving performance, particularly for cold-start
items. 

![Architecture](/posts/20250104_unifying_generative_and_dense_retrieval_for_sequential_recommendation/architecture.png)

# Limitations 


## Resource
[arxiv](https://arxiv.org/pdf/2405.17927)